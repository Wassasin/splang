\documentclass[14pt]{amsart}

\usepackage[british]{babel}

\usepackage{graphicx}
\usepackage{amssymb}
\usepackage{color}
\usepackage{listings}
\usepackage{xspace}
\usepackage{url}

\newcommand{\splang}{\textsc{Splang}\xspace}
\newcommand{\flag}[1]{\texttt{#1}}

\title{The \splang compiler}
\author{Wouter Geraedts (0814857) \and Joshua Moerman (3009048)}
\date{}

% mechanism to handle todos
\newcommand{\todo}[1]{
	\addcontentsline{tdo}{todo}{\protect{#1}}
	$\ast$ \marginpar{\tiny $\ast$ #1}
}
\makeatletter
	\newcommand \listoftodos{\section*{Todo list} \@starttoc{tdo}}
	\newcommand\l@todo[2]{
		\par\noindent \textit{#2}, \parbox{10cm}{#1}\par
	}
\makeatother


\begin{document}
\maketitle

\tableofcontents

\section{Overview}
\subsection{Getting started}
Get the source from \url{https://github.com/Wassasin/splang}. In order to compile it you'll need to install the following haskell packages:
\begin{lstlisting}
$ cabal update
$ cabal install ansi-terminal
$ cabal install edit-distance
$ cabal install derive
\end{lstlisting}

Then to compile \texttt{some.spl}, simply run \texttt{./run some.spl}. This will first compile the compiler (if needed), then compile \texttt{some.spl}. If you only want to tidy \texttt{some.spl} up, you can use \texttt{./parse} instead (this will provide the needed compiler flags).

Use \texttt{./run -h} to see all compiler flags.

\subsection{Compilation phases}
Our compiler uses several compilation phases. A summary is given in table~\ref{tab:overview}. One can stop compiling after a phase by using the corresponding compiler flags \flag{--<phase>-only} and output the result after a phase with \flag{--show-<phase>}, note that not all phases have readable results. In the reading phase every error is a fatal one. In the analysis phase compilation will continue on errors (if possible). Code will only be generated for correct code, unless the \flag{--force-codegen} flag is given.

\begin{table}
\begin{tabular}{l l p{8cm}}
\multicolumn{2}{c}{Phase} & \multicolumn{1}{c}{Description}\\
\hline Reading
 & Lexing & Converts the file to a list of tokens, this strips whitespace and comments. \\
 & Parsing & Parses the list of tokens and generates the AST. \\
\hline Analysis
 & Scoping & Checks usage of identifiers, gives errors on redeclarations and undeclared identifiers. This phase rewrites the AST to contain unique identifiers. \\
 & Typing & Checks and infers types of the program. Rewrites the AST to contain types in each expression. \\
\hline Code gen
 & AST to IR & Converts to the AST to our IR. \\
 & Canonicalize IR & Converts the IR into a IR consisting of basic blocks. \\
 & Generate SSM & Translates the canonical IR into SSM instructions.
\end{tabular}
\caption{Overview of all the phases of the \splang compiler}
\label{tab:overview}
\end{table}


\section{Implementation}
For our SPL-compiler, \splang, we choose \emph{Haskell} as our implementation language. First of all because this is a \emph{functional programming language}, which is really helpful when defining datastructures. Another nice things is the \emph{\texttt{do}-syntax} of Haskell, which makes it very easy (at least to some extend) to propagate for example error messages. Of course this part would also be very easy in a imperative language. Another nice feature is of course nested pattern-matching, which turned out to be really usefull in code generation.

We depend on the libraries mentioned above (other than the library which comes with Haskell). We use \emph{ansi-terminal} for coloured output in the terminal (colour scheme is based on the {\sc Clang} compiler), \emph{edit-distance} for suggestions when the programmer typed a undeclared identifier and \emph{derive} to derive functions/typeclasses for some datastructures.

\section{Parser}
We made our own parsing combinator library. It has infinite lookahead, but when performance matters there are also 1-lookahead combinators. We choose to make our own one, because then we would have full control of error messages and sourecode information. It is implemented in a monadic way.

\subsection{Grammar}
In order to parse the language we had to change the grammar a bit. First of all we added priorities to the different operators, so that the multiplication binds stronger than addition.

Secondly, we generalized the grammar a bit, not only function calls can be an assignment, but also expressions.

We also noted that the given grammar was ambiguous, because of the \emph{dangling else}. We didn't have to change this, nor choose an convention. Our parser has infinite lookahead, so we parse all possibilities and conclude that it is ambiguous, and throw an error.

At last there is the problem of left-recursion in the given grammar. Our parser is left-descent, so we had to do left-factoring. We also had to think about associativity of non-associative operators.

The used grammar is attached in the appendix.

\section{Scoping}
We distinguish three different scopes (from big to small): \emph{global}, \emph{function argument} and \emph{local}. If two identifiers are being declared in the same scope, an error will be thrown, but compilation will continue (to possibly catch more errors). If a identifier is being declared, but it was already declared in a bigger scope, we allow this, but we will give the user a warning (because it is probably not what you want, and might introduce subtle bugs). This is called shadowing, one can still initialize this shadowing identifier with the previous one, as shown here:

\begin{lstlisting}
Int x = 5; // Global
Void foo(){
    Int x = x; // ``Warning: x shadows global x''
               // x will be still initialized with the global x,
               // ie.: x == 5
}
\end{lstlisting}

Globals can be defined in any order you want. This for example allows mutual recursion. This also holds for variable declarations, so one can declare a variable using variables which are defined later. But the compiler does not make a dependency graph, so using a variable which is not defined yet, will result in using uninitialized memory.

As far as scoping is concerned variables can be used as a function, and functions can be passed to other functions. However the type system does not accept this, because the annotated type in the source can never be a function type.

\subsection{Type variable scoping}
Type variables have similar scoping rules. If two typevariables are used in the same scope, they will be exactly the same type. In the following example \texttt{x} and \texttt{y} are of the same type, and therefore the second \texttt{print} will fail to typecheck. (We will later see another reason why this program is not allowed by the compiler).

\begin{lstlisting}
[t] x = [];
[t] y = []; // Same type as x

Void main(){
	print(1:x);    // => x is of type [Int]
	print(True:y); // => y is of type [Bool] => error
}
\end{lstlisting}

There is however an exception to this. We assume that if a function uses a type variable, then it is a polymorphic function. This means that type variables in function arguments are always new, in fact, this is the only way to create a new type variable with the same name. For example:

\begin{lstlisting}
t x = /* ... */

// The following 't' is independent of the above
[t] reverse([t] list){
	/* ... */
}
\end{lstlisting}

Note that type variables and identifiers for variables and functions live in two separate namespaces, so there is never a name clash. (For example we allow: \texttt{x x(x x)\{return x;\}}, which is the identity function.)

\section{Typing}

Our compiler mainly does typechecking, but some type inference is also needed. Type inference is hard to define in a imperative language, as the variables one is infering, might be used differently later on (and mutual recursion is hard). This led to a system which does both type inference and type checking.

We first determine the annotated types of every global variable and function. Then in all expressions and function bodies those annotations are used to infer the actual type at every place in the expression or function body, and with this information the annotated type is checked. We also make sure that \texttt{return} statements really return what they should, and if there is no \texttt{return} statement, the function should return \texttt{Void}.

We only allow \texttt{Void} to occur as a return type of a function. So a list or tuples of \texttt{Void} will give an error. One also cannot supply \texttt{Void} as argument, even when the function is polymorphic. For example \texttt{print(print(5))} will not compile for this reason.

We do not allow the programmer to write this:

\begin{lstlisting}
t x = 5;
\end{lstlisting}

Because it is weird to annotate x with a more general type than it really is. This is a explicit decision we made, technically the compiler is able to infer that \texttt{t == Int}. Allowing this code for variables might seem reasonable, but allowing this also for functions is wrong, as can be seen in the following example:

\begin{lstlisting}
Bool x = f();

// This should not be allowed
t f(){ return 5; }
\end{lstlisting}

Type checking the assignment of the global variable \texttt{y} is ok, since \texttt{f} returns everything you want. So we should not allow the type annotation given to the function \texttt{f}. For consistency we also enforce this for variables. We might at some point in the future allow this flexibility for variables.

\subsection{Formal rules}

\newcommand{\T}{\mathcal{T}}
\newcommand{\U}{\mathcal{U}}
\newcommand{\s}{\ast}
\newcommand{\sn}[1]{\s_{#1}}

As explained before we use the type annotation to support mutual recursion. To check the correctness of this annotation the type is inferred. If an annotation is not as concrete as the actual type of a declaration an error should be displayed. Between this inferred and annotated type a bijection should exist for every free type variable.

For type inferencing we use the following functions:

\begin{itemize}
	\item Type Unification: \\
		$\U \colon \mbox{Type} \rightarrow \mbox{Type} \rightarrow \mbox{Substitution}$
	\item Type Inferencing for declarations: \\
		$\T_{\mbox{d}} \colon \mbox{Context} \rightarrow \mbox{Decl} \rightarrow \mbox{Substitution}$
	\item Type Inferencing for statements and expressions: \\
		$\T \colon \mbox{Context} \rightarrow \mbox{Decl} \rightarrow \mbox{Type} \rightarrow \mbox{Substitution}$
\end{itemize}

We define $\U$ as the function stated in the course slides, and $\T_{\mbox{d}}$ and $\T$ as following:

$\begin{array}{rcl}
	\T_{\mbox{d}}(\Gamma, \mbox{Program}~\vec{d}) & = & \s_n \\
	\sn{n} & = & \T_{\mbox{d}}(\Gamma^{\sn{n-1}}, d_n) \circ \sn{n-1} \\
	& \vdots & \\
	\sn{2} & = & \T_{\mbox{d}}(\Gamma^{\sn{1}}, d_2) \circ \sn{1} \\
	\sn{1} & = & \T_{\mbox{d}}(\Gamma, d_1) \\
	
	\\
	
	\T_{\mbox{d}}(\Gamma, \mbox{VarDecl}~t~x~e) & = & \T(\Gamma, e, \tau) \\
	\forall \emptyset . \, \tau	& = & \Gamma(x) \\

	\\

	\T_{\mbox{d}}(\Gamma, \mbox{FunDecl}~t~x~\vec{\mbox{arg}}~\vec{\mbox{decl}}~\vec{\mbox{stmt}}) & = & \U(\theta^{\sn{1}}, \upsilon^{\sn{1}}) \circ \sn{1} \\
	\upsilon	& = & \vec{\alpha}^{\sn{1}} \rightarrow \beta^{\sn{1}} \\
	\sn{1}		& = & \sn{(2,n)} \\
	\sn{(2,n)}	& = & \T(\Gamma'^{\sn{(2,n-1)}}, \mbox{stmt}_n, \beta^{\sn{(2,n-1)}}) \circ \sn{(2,n-1)} \\
	& \vdots & \\
	\sn{(2,2)}	& = & \T(\Gamma'^{\sn{(2,1)}}, \mbox{stmt}_2, \beta^{\sn{(2,1)}}) \circ \sn{(2,1)} \\
	\sn{(2,1)}	& = & \T(\Gamma'^{\sn{3}}, \mbox{stmt}_1, \beta^{\sn{3}}) \circ \sn{(3,n)} \\
	\sn{(3,n)}	& = & \T_{\mbox{d}}(\Gamma'^{\sn{(3,n-1)}}, \mbox{decl}_n) \circ \sn{(3,n-1)} \\
	& \vdots & \\
	\sn{(3,2)}	& = & \T_{\mbox{d}}(\Gamma'^{\sn{(3,1)}}, \mbox{decl}_2) \circ \sn{(3,1)} \\
	\sn{(3,1)}	& = & \T_{\mbox{d}}(\Gamma'^{\sn{4}}, \mbox{decl}_1) \circ \sn{4} \\
	\Gamma'		& = & \Gamma' [\mbox{arg}_n.x := \alpha_n] \\
	& \vdots & \\
	\Gamma'		& = & \Gamma' [\mbox{arg}_2.x := \alpha_2] \\
	\Gamma'		& = & \Gamma' [\mbox{arg}_1.x := \alpha_1] \\
	& & \mbox{where}~\beta~\mbox{fresh} \\
	& & \mbox{and}~\vec{\alpha}~\mbox{fresh for all~} \vec{\mbox{arg}} \\
\end{array}$

$\begin{array}{rcl}
	\T(\Gamma, \mbox{Expr}~e, \sigma) & = & \T(\Gamma, e, \alpha) \\
	& & \mbox{where}~\alpha~\mbox{fresh} \\

	\\

	\T(\Gamma, \mbox{Scope}~\vec{\mbox{stmt}}, \sigma) & = & \sn{n} \\
	\sn{n} & = & \T(\Gamma^{\sn{n-1}}, \mbox{stmt}_n, \sigma^{\sn{n-1}}) \circ \sn{n-1} \\
	& \vdots & \\
	\sn{2} & = & \T(\Gamma^{\sn{1}}, \mbox{stmt}_2, \sigma^{\sn{1}}) \circ \sn{1} \\
	\sn{1} & = & \T(\Gamma, \mbox{stmt}_1, \sigma) \\

	\\

	\T(\Gamma, \mbox{If}~e~\mbox{stmtt}, \sigma) & = & \T(\Gamma^{\s}, \mbox{stmtt}, \sigma^{\s}) \circ \s \\
	\s & = & \T(\Gamma, e, \mbox{Bool}) \\

	\\

	\T(\Gamma, \mbox{IfElse}~e~\mbox{stmtt}~\mbox{stmte}, \sigma) & = & \T(\Gamma^{\s}, \mbox{stmte}, \sigma^{\s}) \circ \s \\
	\s & = & \T(\Gamma^{\sn{1}}, \mbox{stmtt}, \sigma^{\sn{1}}) \circ \sn{1} \\
	\sn{1} & = & \T(\Gamma, e, \mbox{Bool}) \\

	\\

	\T(\Gamma, \mbox{While}~e~\mbox{stmt}, \sigma) & = & \T(\Gamma^{\s}, \mbox{stmt}, \sigma^{\s}) \circ \s \\
	\s & = & \T(\Gamma, e, \mbox{Bool}) \\

	\\

	\T(\Gamma, \mbox{Assignment}~i~e, \sigma) & = & \T(\Gamma, \mbox{e}, \tau [\vec{\alpha} := \vec{\beta}] ) \\
	\forall \vec{\alpha} .\, \tau & = & \Gamma(i) \\
	& & \mbox{where}~\vec{\beta}~\mbox{fresh} \\

	\\

	\T(\Gamma, \mbox{Return}, \sigma) & = & \U(\sigma, \mbox{Void}) \\

	\\

	\T(\Gamma, \mbox{Return}~e, \sigma) & = & \U(\sigma^{\s}, \alpha^{\s}) \circ \s \\
	\s & = & \T(\Gamma, e, \alpha) \\
	& & \mbox{where}~\alpha~\mbox{fresh} \\
\end{array}$

$\begin{array}{rcl}
	\T(\Gamma, \mbox{Var}~i, \sigma) & = & \U(\sigma, \tau [\vec{\alpha} := \vec{\beta}] ) \\
	\forall \vec{\alpha} .\, \tau & = & \Gamma(i) \\
	& & \mbox{where}~\vec{\beta}~\mbox{fresh} \\
	
	\\
	
	\T(\Gamma, e_1 \odot e_2, \sigma) & = & \U(\sigma^{\s}, \tau^{\s}) \\
	\s	& = & \T(\Gamma^{\sn{1}}, e_2, \gamma_2^{\sn{1}}) \circ \sn{1} \\
	\sn{1}	& = & \T(\Gamma, e_1, \gamma_1) \\
	& & \mbox{where}~\odot : \gamma_1 \rightarrow \gamma_2 \rightarrow \tau \\
	
	\\
	
	\T(\Gamma, \boxdot e, \sigma) & = & \U(\sigma^{\s}, \tau^{\s}) \\
	\s	& = & \T(\Gamma, e, \gamma) \\
	& & \mbox{where}~\boxdot : \gamma \rightarrow \tau \\
	
	\\
	
	\T(\Gamma, \mbox{Int}~i, \sigma) & = & \U(\sigma, \mbox{Int}) \\

	\\
	
	\T(\Gamma, \mbox{Bool}~b, \sigma) & = & \U(\sigma, \mbox{Bool}) \\
	
	\\
	
	\T(\Gamma, f(e_1, \hdots, e_n), \sigma) & = & \s \\
	\s		& = & \U(\sigma^{\sn{(1, n)}}, \rho^{\sn{(1, n)}}) \circ \sn{(1, n)} \\
	\sn{(1, n)}	& = & \T(\Gamma^{\sn{(1, n-1)}}, e_n, \pi_n^{\sn{(1, n-1)}}) \circ \sn{(2, n-1)} \\
	& \vdots & \\
	\sn{(1, 2)}	& = & \T(\Gamma^{\sn{(1, 1)}}, e_2, \pi_2^{\sn{(1, 1)}}) \circ \sn{(1, 1)} \\
	\sn{(1, 1)}	& = & \T(\Gamma^{\sn{2}}, e_1, \pi_1^{\sn{2}}) \circ \sn{2} \\
	\sn{2}		& = & \U(\tau[\vec{\alpha} := \vec{\beta}], \pi_1 \rightarrow \hdots \rightarrow \pi_n \rightarrow \rho) \\
	\forall \vec{\alpha} .\, \tau & = & \Gamma(f) \\
	& & \mbox{where}~\vec{\alpha}, \vec{\beta}, \vec{\pi}, \rho~\mbox{fresh} \\
	
	\\
	
	\T(\Gamma, (e_1, e_2), \sigma)	& = & \U(\sigma^{\s}, (\alpha_1, \alpha_2)^{\s}) \circ \s \\
	\s				& = & \T(\sigma^{\sn{1}}, e_2, \alpha_2^{\sn{1}}) \circ \sn{1} \\
	\sn{1}				& = & \T(\sigma, e_1, \alpha_1) \\
	& & \mbox{where}~\alpha_1, \alpha_2~\mbox{fresh} \\
	
	\\
	
	\T(\Gamma, [], \sigma)	& = & \U(\sigma, [\alpha]) \\
	& & \mbox{where}~\alpha~\mbox{fresh} \\
\end{array}$

\section{Semantics}
The semantics are straight forward. Integer arithmetic is the usual arithmetic, with overflow behaviour and division rounding defined by the target (i.e. by the SSM). Also the boolean operators work as usual. We don't do short-circuiting, so in the following code \texttt{f} will be called:
\begin{lstlisting}
if(False && f()){
	// ...
}
\end{lstlisting}

If one calls multiple statements in one statements, generally those functions will be called from left to right, unless one of the functions is nested in another function call. So in the following example \texttt{a}, \texttt{b} and \texttt{c} are called (in this order) before \texttt{f}:
\begin{lstlisting}
	Int x = f(a(), b(), c());
\end{lstlisting}

All functions take arguments by value. There are no mechanism to update a datastructure (i.e. tuple or list). So one always has to construct such an object fully.

Polymorphic functions will be instantiated for each use. This is very alike the templating system in C++. We decided to do this because we also want to target LLVM bitcode, which is strongly typed (without polymorphism). Of course we can easily write a program which requires infinitely many types, for example:

\begin{lstlisting}
Void f(t x){
	f((x,x));
}

Void main(){
	f(5);
}
\end{lstlisting}

However such programs will never terminate, so they are not very useful in practice. In order to guarantee that the \splang compiler terminates, we will only instantiate untill a certain depth is reached. We regard this as a small drawback, but the advantage of this is that we know the exact concrete types when generating code, and we can easily decide to call a specific version of the function.

\section{SSM}
% what should this chapter contain:
% A chapter explaining the compilation schemes used in your compiler. A
% concise informal or semiformal description suï¬ƒces, so a formal description
% of the compilation scheme is welcome, but not required. Typical things to
% 5explain here are calling conventions, stack management, stack layout, heap
% layout, and heap management.

\subsection{Calling convention and stack management}
When calling a function, the caller makes sure pushes the arguments on the stack, in reverse order. The callee is allowed to change these in its calculation, and will return via the return register (RR). It's then the callers job to clean up the pushed arguments.

For the call the \texttt{bsr} and \texttt{ret} instructions are used. So on top of the arguments there will be a return address. The callee then also pushes the mark pointer (MP) on the stack and updates the MP to the current stack pointer (SP). On return the callee resets the original MP.

\todo{Discuss global variables}

\subsection{Tuples and lists}
Tuples will be flattened, and used as usual objects on the stack. So for example a functions that takes a tuple of two elements will in fact simply take two arguments. This is possible because we always know the exact type which is being used, and hence the exact size of such a tuple. \todo{Discuss how to return tuples}

Lists will be pushed on the heap as a linked list. So the value we have on the stack is a pointer to the first element of the list.

\section{Tests}
All tests are performed with the \texttt{--show-input --show-stages} flags, and all colors are stripped. The output is a pretty printed version of the program augmented with both the scoping results (after every identifier), and typing (before every declaration). For every \texttt{.spl} file, there is a \texttt{.spl.txt} file with gray output. The coloured output is also attached in a different pdf file.

\subsection{Parsing}
\begin{itemize}
	\item[fail\_ambi] This program can be read ambiguously. Note that the compiler detects this, and prints out all possible interpretations. However this error is not fatal, and the compilation continues, and catches a typing error: the \texttt{if}-construct expects a \texttt{Bool}, but an \texttt{Int} was given.
	\item[pass\_parser] This program shows that the compiler correctly handles associativity and priorities of infix operators.
\end{itemize}
\subsection{Scoping}
\begin{itemize}
	\item[warn\_shadowing] This shows the warnings one get when redeclaring the same identifier in a more specific scope. Note that the functions \texttt{x} and \texttt{y} are both identity functions.
	\item[fail\_identifier\_errors] If one redeclares identifiers in the same scope, an non-fatal error will be given. Note that compilation continues and more errors are found. If an identifiers is undeclared, a suggestion is given by the compiler.
\end{itemize}
\subsection{Typing}
\begin{itemize}
	\item[fail\_arguments] Shows the error messages you get when you don't supply the right amount of arguments. Also note that the arguments that \emph{are} supplied, are also type checked.
	\item[fail\_void\_no\_return] Shows that we do not accept a returning function without return statement. Specifically, we see that the compiler infers that \texttt{foo} returns \texttt{Void}, instead of \texttt{Int}. Furthermore we see that we cannot use values of type \texttt{Void}.
	\item[pass\_merge\_sort] Shows that the compiler is capable of handling polymorphism. And is nicely shows a real world example, and also shows mutual recursion.
	\item[pass\_reverse] Shows a basic reverse function. It is also used on a list of lists.
	\item[fail\_empty\_list] Shows our compilers output on the \emph{Empty list} example discussed above. Note that the type \texttt{t} is used in different ways (both \texttt{Int} and \texttt{Bool}).
	\item[pass\_polymorphism] Shows polymorphism and also scoping of type variables.
\end{itemize}
\subsection{Code generation}
\begin{itemize}
	\item[pass_recfib] Tests recursion and simple integer arithmetic.
	\item[pass_order] Tests the order of evaluation
	\item[pass_loop] Tests while loops.
	\todo{Add tests with tuples and lists}
\end{itemize}

\section{Reflection}
In the first phase Wouter made the lexer, and Joshua made a first implementation of the parser in \emph{Parsec}, however we decided to write our own parsing library. This was mainly done by Wouter. In the second phase Joshua mainly worked on the scoping and type annotations, Wouter mainly on the type inference. All design choices were discussed together to ensure a working whole. And also in some cases one found a bug in the others code. So eventually all code understood by both of us.

For a very precise description of who did what, one can have a look at our repository:

\url{https://github.com/Wassasin/splang}

\newpage
\appendix
\section{Grammar}

\newcommand{\tok}[1]{`\texttt{#1}'}
\newcommand{\I}{\hspace{0.1cm}$\mid$\hspace{0.2cm}}

\begin{tabular}[t]{p{2.5cm} c p{10cm}}
Prog		& := & Decl$^+$					\\
Decl		& := & VarDecl \I FunDecl			\\
VarDecl		& := & Type id \tok{=} Exp \tok{;}		\\
FunDecl		& := & RetType id \tok{(} [ FArgs ] \tok{)} \tok{\{} VarDecl* Stmt$^+$ \tok{\}} \\
RetType		& := & Type \I \tok{Void}			\\
Type		& := & \tok{Int} \I \tok{Bool} \I id		\\
		& \I & \tok{(} Type \tok{,} Type \tok{)}	\\
		& \I & \tok{[} Type \tok{]}			\\
FArgs		& := & Type id \I Type id \tok{,} Fargs		\\
&&\\
Stmt		& := & \tok{\{} Stmt* \tok{\}}			\\
		& \I & \tok{if} \tok{(} Exp \tok{)} Stmt	\\
		& \I & \tok{if} \tok{(} Exp \tok{)} Stmt \tok{else} Stmt \\
		& \I & \tok{while} \tok{(} Exp \tok{)} Stmt 	\\
		& \I & id \tok{=} Exp \tok{;}			\\
		& \I & Exp \tok{;}				\\
		& \I & \tok{return} Exp \tok{;}			\\
&&\\
Exp		& := & Term0					\\
Term0		& := & Term1 \I Term1 Op2Bool Term0		\\
Term1		& := & Term2 \I Term2 Op2Equal Term1		\\
Term2		& := & Term3 \I OpNot Term2			\\
Term3		& := & Term4 \I Term4 OpCons Term3		\\
Term4		& := & Term5 \I Term5 Term4b			\\
Term4b		& := & Op2Add Term5 Term4b \I $\epsilon$	\\
Term5		& := & Term6 \I Term6 Term5b			\\
Term5b		& := & Op2Mult Term6 Term5b \I $\epsilon$	\\
Term6		& := & OpNegative Term6 \I Term7		\\
Term7		& := & int					\\
		& \I & \tok{(} Exp \tok{)}			\\
		& \I & \tok{(} Exp \tok{,} Exp \tok{)}		\\
		& \I & \tok{False}				\\
		& \I & \tok{True}				\\
		& \I & id					\\
		& \I & FunCall					\\
		& \I & \tok{[]}					\\
&&\\
FunCall		& := & id \tok{(} [ ActArgs ] \tok{)}		\\
ActArgs		& := & Exp \I Exp \tok{,} ActArgs		\\
&&\\
Op2Mult		& := & \tok{$\ast$} \I \tok{/} \I \tok{\%} 	\\
Op2Add		& := & \tok{+} \I \tok{-}			\\
Op2Cons		& := & \tok{:}					\\
Op2Equal	& := & \tok{==} \I \tok{<} \I \tok{>} \I \tok{<=} \I \tok{>=} \I \tok{!=} \\
Op2Bool		& := & \tok{\&\&} \I \tok{||}			\\
&&\\
OpNot		& := & \tok{!}					\\
OpNegative	& := & \tok{-}					\\
&&\\
int		& := & digit$^+$				\\
id		& := & alpha \I alpha id'			\\
id'		& := & id' \tok{\_} \I id' alphaNum
\end{tabular}

\listoftodos

\end{document}
